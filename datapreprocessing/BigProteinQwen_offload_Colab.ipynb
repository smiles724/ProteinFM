{"cells":[{"cell_type":"markdown","id":"11360105","metadata":{"id":"11360105"},"source":["\n","# BigProtein-Qwen2.5 — Step‑by‑Step Test Notebook (Colab)\n","This notebook lets you **test each component** of the protein‑conditioned Qwen2.5 pipeline *before* running full training.  \n","It mirrors the main script logic, but runs **function‑by‑function** so you can see errors early with clear tracebacks.\n","\n","> **Files expected in the working directory** (upload or mount a folder containing them):  \n","> - `bigmodel_joint_train.py`  \n","> - `protein_encoder.py`  \n","> - `structure_encoder.py`\n"]},{"cell_type":"code","source":["#@title Mount Google Drive\n","from pathlib import Path\n","from huggingface_hub import snapshot_download\n","import os, json, pickle, pandas as pd\n","from tqdm import tqdm\n","from rich import print as rprint"],"metadata":{"id":"IUYulnhL8NM-","executionInfo":{"status":"ok","timestamp":1759412479527,"user_tz":240,"elapsed":566,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}}},"id":"IUYulnhL8NM-","execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","WORKDIR = Path(\"/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines\")\n","%cd {WORKDIR}\n","\n","from pathlib import Path\n","BASE_DIR = Path(\"/content/drive/MyDrive/LLM/Bioreasoner/data/hf/proteinDT\")\n","OUT_DIR  = BASE_DIR / \"sft_test_demo\"\n","print(f\"Using Google Drive folder as BASE_DIR: {BASE_DIR}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxEz1S18Ys00","executionInfo":{"status":"ok","timestamp":1759412482087,"user_tz":240,"elapsed":2562,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"2baad612-1b15-49ce-fc6d-42bfa49ec567"},"id":"DxEz1S18Ys00","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines\n","Using Google Drive folder as BASE_DIR: /content/drive/MyDrive/LLM/Bioreasoner/data/hf/proteinDT\n"]}]},{"cell_type":"markdown","id":"ef586a49","metadata":{"id":"ef586a49"},"source":["\n","## 0) Runtime & Installs\n","If you're on Google Colab, run this cell to install dependencies.\n"]},{"cell_type":"code","source":["# # Check GPU\n","# !nvidia-smi\n","\n","# #@title Install dependencies (Torch + requirements_offload)\n","# import subprocess, sys, os, json, textwrap\n","# from pathlib import Path\n","\n","# REQ = Path(\"requirements_offload.txt\")\n","# if not REQ.exists():\n","#     print(\"requirements_offload.txt not found here. Listing directory:\")\n","#     print(os.listdir(\".\"))\n","\n","# # Fresh pip + libs (PyTorch CUDA 12.1 build + matching libs)\n","# %pip -q install --upgrade pip\n","# %pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n","#   torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n","# %pip -q install transformers==4.56.1 huggingface_hub==0.35.0 tqdm safetensors\n","\n","# # Core deps\n","# !pip -q install -r requirements_offload.txt\n","\n","# import torch, transformers, accelerate, huggingface_hub, tqdm as _tqdm\n","# print(\"torch:\", torch.__version__)\n","# print(\"transformers:\", transformers.__version__)\n","# print(\"accelerate:\", accelerate.__version__)\n","# print(\"huggingface_hub:\", huggingface_hub.__version__)"],"metadata":{"id":"W8upz3dOoYqH","executionInfo":{"status":"ok","timestamp":1759412482091,"user_tz":240,"elapsed":3,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}}},"id":"W8upz3dOoYqH","execution_count":3,"outputs":[]},{"cell_type":"code","source":["# If you already pinned these in the runtime, you can skip reinstalling.\n","!pip -q install --upgrade pip\n","!pip -q install transformers==4.56.1 huggingface_hub==0.35.0 accelerate>=0.33.0 safetensors tqdm bitsandbytes\n","\n","import os, torch, subprocess, json, math, re, time, sys\n","from pathlib import Path\n","\n","# Helpful for CUDA fragmentation\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512,expandable_segments:True\"\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","# Show GPU\n","!nvidia-smi || true\n","print(\"torch:\", torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GZqBJCH9TGa","executionInfo":{"status":"ok","timestamp":1759412487520,"user_tz":240,"elapsed":5425,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"1f09a2a6-9ad0-477b-effb-f15626af4d9a"},"id":"-GZqBJCH9TGa","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Oct  2 13:41:26 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n","| N/A   32C    P0             51W /  400W |       0MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","torch: 2.8.0+cu126\n"]}]},{"cell_type":"markdown","source":["torch            : 2.8.0+cu126\n","\n","transformers     : 4.56.1\n","\n","huggingface_hub  : 0.35.0\n","\n","✅ Top-level EsmForMaskedLM import OK"],"metadata":{"id":"f9G7pU_Rp4mF"},"id":"f9G7pU_Rp4mF"},{"cell_type":"markdown","source":["\n","## 1) Loading Encoder Checkpoints"],"metadata":{"id":"3ZDFip2psPXw"},"id":"3ZDFip2psPXw"},{"cell_type":"code","execution_count":5,"id":"fd2cdf79","metadata":{"id":"fd2cdf79","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759412487526,"user_tz":240,"elapsed":5,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"893c366f-878e-4e1b-e6bf-fc778052d839"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines\n","✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/protein2desc_sft_ALLFOUR_c000-009_fullcot.jsonl\n","✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/esm2_t12_35M_UR50D\n","✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/foldseek_t12_35M\n","✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/ProTrek_35M.pt\n","✓ exists: True /content/drive/MyDrive/LLM/Bioreasoner/testing_notebooks/runs_colab_test\n"]}],"source":["\n","# === LLM & Encoders ===\n","MODEL_NAME         = \"Qwen/Qwen2.5-0.5B-Instruct\"   # Small-ish for Colab testing\n","PROTEIN_CONFIG = \"/content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/esm2_t12_35M_UR50D\"\n","STRUCTURE_CONFIG = \"/content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/foldseek_t12_35M\"\n","PROTREK_CKPT    = \"/content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/ProTrek_35M.pt\"\n","PROJECT_DIR = \"/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines\"\n","TRAIN_FILE = \"/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/protein2desc_sft_ALLFOUR_c000-009_fullcot.jsonl\"\n","VAL_FILE   = None  # or path\n","OUT_DIR = \"/content/drive/MyDrive/LLM/Bioreasoner/testing_notebooks/runs_colab_test\"\n","\n","#%cd /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines\n","SCRIPT = WORKDIR / \"train_prefix_qwen_fsdp_offload1.py\"\n","\n","for p in [PROJECT_DIR, TRAIN_FILE, PROTEIN_CONFIG, STRUCTURE_CONFIG, PROTREK_CKPT, OUT_DIR]:\n","    print(\"✓ exists:\", os.path.exists(p), p)\n","\n"]},{"cell_type":"code","source":["SAVE_DIR = \"/content/drive/MyDrive/LLM/Bioreasoner/colab_runs/qwen05b_prefix_test\"\n","PROT_SLOT, STRU_SLOT = 1, 3\n","# Training knobs (friendly defaults for single-GPU offload on Colab)\n","BATCH_SIZE   = 1\n","ACCUM_STEPS  = 8\n","MAX_LEN      = 1024\n","PREFIX_LEN   = 4\n","PREFIX_GATE  = 1.0\n","EPOCHS       = 1\n","LR           = 1e-4\n","OPTIMIZER    = \"adamw\"   # \"adamw\" | \"adam8bit\" | \"adafactor\"\n","TRAIN_ENCODS = True         # backprop encoders (slower; set False to freeze)\n","FREEZE_LLM   = False\n","\n","SAVE_DIR     = \"/content/checkpoints/qwen7b_bf16_offload\"\n","SAVE_EVERY   = 0            # 0 = only save final\n","EVAL_EVERY   = 0            # 0 = no mid-epoch eval\n","\n","# Check files exist\n","for p in [SCRIPT, TRAIN_FILE, PROTEIN_CONFIG, STRUCTURE_CONFIG, PROTREK_CKPT]:\n","    print(\"OK:\", p) if Path(p).exists() else print(\"MISSING:\", p)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET3YTyMxpKOS","executionInfo":{"status":"ok","timestamp":1759412487534,"user_tz":240,"elapsed":6,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"3f397209-1400-4759-baf8-7d4d7213bcb8"},"id":"ET3YTyMxpKOS","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["OK: /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/train_prefix_qwen_fsdp_offload1.py\n","OK: /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/protein2desc_sft_ALLFOUR_c000-009_fullcot.jsonl\n","OK: /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/esm2_t12_35M_UR50D\n","OK: /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/foldseek_t12_35M\n","OK: /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/ProTrek_35M.pt\n"]}]},{"cell_type":"code","source":["# SUBTRAIN_FILE = os.path.join(PROJECT_DIR, \"train_subset_100.jsonl\")\n","\n","# # Write first 1000 non-empty lines to subset\n","# count = 0\n","# with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as fin, open(SUBTRAIN_FILE, \"w\", encoding=\"utf-8\") as fout:\n","#     for line in fin:\n","#         if not line.strip():\n","#             continue\n","#         fout.write(line)\n","#         count += 1\n","#         if count >= 100:\n","#             break\n","\n","# print(\"Wrote subset lines:\", count, \"->\", SUBTRAIN_FILE)"],"metadata":{"id":"-Qib_xuxpMXY","executionInfo":{"status":"ok","timestamp":1759412487539,"user_tz":240,"elapsed":2,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}}},"id":"-Qib_xuxpMXY","execution_count":7,"outputs":[]},{"cell_type":"code","source":["import json\n","from statistics import mean\n","\n","N = 0\n","prompt_chars = []\n","resp_chars   = []\n","with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        if not line.strip():\n","            continue\n","        ex = json.loads(line)\n","        if \"prompt\" not in ex or \"response\" not in ex:\n","            continue\n","        N += 1\n","        prompt_chars.append(len(ex[\"prompt\"]))\n","        resp_chars.append(len(ex[\"response\"]))\n","\n","def pct(x, p):\n","    i = max(0, min(len(x)-1, int(p*len(x))))\n","    return sorted(x)[i]\n","\n","print(f\"Samples: {N}\")\n","if N:\n","    print(f\"Prompt chars — mean={mean(prompt_chars):.0f}, min={min(prompt_chars)}, p50={pct(prompt_chars,0.5)}, p90={pct(prompt_chars,0.9)}, p95={pct(prompt_chars,0.95)}, max={max(prompt_chars)}\")\n","    print(f\"Response chars — mean={mean(resp_chars):.0f}, min={min(resp_chars)}, p50={pct(resp_chars,0.5)}, p90={pct(resp_chars,0.9)}, p95={pct(resp_chars,0.95)}, max={max(resp_chars)}\")\n","    approx_tokens = sum((p+r)/4 for p,r in zip(prompt_chars, resp_chars))\n","    print(f\"~Estimated tokens/epoch (capless, 4 chars/token): {int(approx_tokens):,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xaQGcwbU-F0S","executionInfo":{"status":"ok","timestamp":1759412487753,"user_tz":240,"elapsed":213,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"069d2b6d-cbce-410d-80bc-250b063b6710"},"id":"xaQGcwbU-F0S","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Samples: 7782\n","Prompt chars — mean=337, min=337, p50=337, p90=337, p95=337, max=337\n","Response chars — mean=1530, min=601, p50=1453, p90=1992, p95=2282, max=10615\n","~Estimated tokens/epoch (capless, 4 chars/token): 3,632,726\n"]}]},{"cell_type":"code","source":["ACCEL_CFG = WORKDIR / \"accelerate_cpu_offload_bf16.yaml\"\n","ACCEL_CFG.write_text(\"\"\"\\\n","compute_environment: LOCAL_MACHINE\n","distributed_type: FSDP\n","mixed_precision: bf16\n","num_processes: 1\n","downcast_bf16: false\n","fsdp_config:\n","  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP\n","  fsdp_sharding_strategy: FULL_SHARD\n","  fsdp_backward_prefetch_policy: BACKWARD_POST\n","  fsdp_state_dict_type: FULL_STATE_DICT\n","  fsdp_use_orig_params: true\n","  fsdp_offload_params: true\n","  fsdp_cpu_offload: true\n","\"\"\")\n","print(\"Wrote:\", ACCEL_CFG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rz8FPyup-elj","executionInfo":{"status":"ok","timestamp":1759412487756,"user_tz":240,"elapsed":4,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"094d29ba-c5ac-43be-c6f5-533d2f37a250"},"id":"Rz8FPyup-elj","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote: /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/accelerate_cpu_offload_bf16.yaml\n"]}]},{"cell_type":"code","source":["import accelerate, sys\n","print(\"accelerate:\", accelerate.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udjZiG9eB2b2","executionInfo":{"status":"ok","timestamp":1759412487792,"user_tz":240,"elapsed":35,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"070eaf68-556b-4289-9601-1a0d73e13a36"},"id":"udjZiG9eB2b2","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerate: 1.10.1\n"]}]},{"cell_type":"code","source":["import subprocess, sys, math, time, re\n","from tqdm import tqdm\n","\n","# Compute approx optimizer-steps per epoch for progress (world_size=1 on Colab)\n","steps_per_rank = math.ceil(N / max(1, BATCH_SIZE))\n","opt_steps_per_epoch = math.ceil(steps_per_rank / max(1, ACCUM_STEPS)) * max(1, EPOCHS)\n","print(f\"~Optimizer steps/epoch: ≈{opt_steps_per_epoch} (B={BATCH_SIZE}, accum={ACCUM_STEPS}, N={N})\")\n","\n","cmd = [\n","    \"accelerate\", \"launch\", \"--config_file\", str(ACCEL_CFG),\n","    str(SCRIPT),\n","    \"--train-file\", TRAIN_FILE,\n","    \"--model-name\", MODEL_NAME,\n","    \"--protein-config\", PROTEIN_CONFIG,\n","    \"--structure-config\", STRUCTURE_CONFIG,\n","    \"--protrek-ckpt\", PROTREK_CKPT,\n","    \"--prot-slot\", str(PROT_SLOT), \"--stru-slot\", str(STRU_SLOT),\n","    \"--batch-size\", str(BATCH_SIZE),\n","    \"--accum-steps\", str(ACCUM_STEPS),\n","    \"--max-len\", str(MAX_LEN),\n","    \"--prefix-len\", str(PREFIX_LEN),\n","    \"--prefix-gate\", str(PREFIX_GATE),\n","    \"--epochs\", str(EPOCHS),\n","    \"--lr\", str(LR),\n","    \"--optimizer\", OPTIMIZER,\n","    \"--save-dir\", SAVE_DIR,\n","    \"--save-every\", str(SAVE_EVERY),\n","]\n","\n","if TRAIN_ENCODS:\n","    cmd.append(\"--train-encoders\")\n","if FREEZE_LLM:\n","    cmd.append(\"--freeze-llm\")\n","if VAL_FILE:\n","    cmd += [\"--val-file\", VAL_FILE]\n","if EVAL_EVERY:\n","    cmd += [\"--eval-every\", str(EVAL_EVERY)]\n","\n","print(\"Launching:\\n\", \" \".join(cmd))\n","\n","# Run and live-parse \"step ...\" lines for progress\n","proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1, text=True)\n","\n","step_re = re.compile(r\"step\\s+(\\d+)\\s*\\|\")  # matches: step 50 | loss=...\n","pbar = tqdm(total=opt_steps_per_epoch, desc=\"optimizer steps\", dynamic_ncols=True)\n","last_step_seen = 0\n","start = time.time()\n","\n","try:\n","    for line in proc.stdout:\n","        # Show raw logs\n","        sys.stdout.write(line)\n","        sys.stdout.flush()\n","        # Try to parse \"step N\"\n","        m = step_re.search(line)\n","        if m:\n","            s = int(m.group(1))\n","            if s > last_step_seen:\n","                pbar.update(s - last_step_seen)\n","                last_step_seen = s\n","except KeyboardInterrupt:\n","    proc.terminate()\n","finally:\n","    proc.wait()\n","    # If no step logs were printed (e.g., very small run), mark as done\n","    if last_step_seen < opt_steps_per_epoch:\n","        pbar.update(opt_steps_per_epoch - last_step_seen)\n","    pbar.close()\n","\n","print(f\"Done. Elapsed ~{int(time.time()-start)}s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXfahvI8-nCk","executionInfo":{"status":"ok","timestamp":1759412546207,"user_tz":240,"elapsed":58406,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"494e742a-ab5a-4e05-ffc4-3b34796d9d31"},"id":"yXfahvI8-nCk","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["~Optimizer steps/epoch: ≈973 (B=1, accum=8, N=7782)\n","Launching:\n"," accelerate launch --config_file /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/accelerate_cpu_offload_bf16.yaml /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/train_prefix_qwen_fsdp_offload1.py --train-file /content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/protein2desc_sft_ALLFOUR_c000-009_fullcot.jsonl --model-name Qwen/Qwen2.5-0.5B-Instruct --protein-config /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/esm2_t12_35M_UR50D --structure-config /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/foldseek_t12_35M --protrek-ckpt /content/drive/MyDrive/LLM/Bioreasoner/protrek/weights/ProTrek_35M/ProTrek_35M.pt --prot-slot 1 --stru-slot 3 --batch-size 1 --accum-steps 8 --max-len 1024 --prefix-len 4 --prefix-gate 1.0 --epochs 1 --lr 0.0001 --optimizer adam8bit --save-dir /content/checkpoints/qwen7b_bf16_offload --save-every 0 --train-encoders\n"]},{"output_type":"stream","name":"stderr","text":["\roptimizer steps:   0%|          | 0/973 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["2025-10-02 13:41:43.790264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-10-02 13:41:43.809257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1759412503.831102   21964 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1759412503.838160   21964 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1759412503.855389   21964 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759412503.855413   21964 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759412503.855416   21964 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759412503.855419   21964 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-10-02 13:41:43.861236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","Device: cuda:0 | distributed: 1 gpu(s) | mp=bf16\n","Loaded LLM: Qwen/Qwen2.5-0.5B-Instruct | hidden_size=896\n","[ProteinEncoder] loaded from slot 1 | missing=0 unexpected=0\n","[StructureEncoder] loaded from slot 3 | missing=0 unexpected=0\n","/usr/local/lib/python3.12/dist-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n","  warnings.warn(\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/train_prefix_qwen_fsdp_offload1.py\", line 553, in <module>\n","[rank0]:     train(args)\n","[rank0]:   File \"/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/train_prefix_qwen_fsdp_offload1.py\", line 435, in train\n","[rank0]:     optimizer.step()\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/accelerate/optimizer.py\", line 179, in step\n","[rank0]:     self.optimizer.step(closure)\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 516, in wrapper\n","[rank0]:     out = func(*args, **kwargs)\n","[rank0]:           ^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n","[rank0]:     return func(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/optim/optimizer.py\", line 291, in step\n","[rank0]:     self.update_step(group, p, gindex, pindex)\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n","[rank0]:     return func(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/optim/optimizer.py\", line 568, in update_step\n","[rank0]:     F.optimizer_update_8bit_blockwise(\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/functional.py\", line 1359, in optimizer_update_8bit_blockwise\n","[rank0]:     is_on_gpu([p, g, state1, state2, qmap1, qmap2, absmax1, absmax2])\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/functional.py\", line 360, in is_on_gpu\n","[rank0]:     raise RuntimeError(\n","[rank0]: RuntimeError: All input tensors need to be on the same GPU, but found some tensors to not be on a GPU:\n","[rank0]:  [(torch.Size([896, 2048]), device(type='cpu')), (torch.Size([896, 2048]), device(type='cpu')), (torch.Size([896, 2048]), device(type='cpu')), (torch.Size([896, 2048]), device(type='cpu')), (torch.Size([256]), device(type='cpu')), (torch.Size([256]), device(type='cpu')), (torch.Size([7168]), device(type='cpu')), (torch.Size([7168]), device(type='cpu'))]\n","E1002 13:42:24.627000 21863 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 21964) of binary: /usr/bin/python3\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/accelerate\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n","    args.func(args)\n","  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1222, in launch_command\n","    multi_gpu_launcher(args)\n","  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 853, in multi_gpu_launcher\n","    distrib_run.run(args)\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 892, in run\n","    elastic_launch(\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 143, in __call__\n","    return launch_agent(self._config, self._entrypoint, list(args))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 277, in launch_agent\n","    raise ChildFailedError(\n","torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n","============================================================\n","/content/drive/MyDrive/LLM/Bioreasoner/testing_pipelines/train_prefix_qwen_fsdp_offload1.py FAILED\n","------------------------------------------------------------\n","Failures:\n","  <NO_OTHER_FAILURES>\n","------------------------------------------------------------\n","Root Cause (first observed failure):\n","[0]:\n","  time      : 2025-10-02_13:42:24\n","  host      : 6b6887df008e\n","  rank      : 0 (local_rank: 0)\n","  exitcode  : 1 (pid: 21964)\n","  error_file: <N/A>\n","  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["optimizer steps: 100%|██████████| 973/973 [00:58<00:00, 16.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Done. Elapsed ~58s\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os, glob\n","print(\"Checkpoints in:\", SAVE_DIR)\n","for p in sorted(glob.glob(os.path.join(SAVE_DIR, \"*.pt\"))):\n","    print(\" -\", p)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-x-YfAX-o5Q","executionInfo":{"status":"ok","timestamp":1759412546214,"user_tz":240,"elapsed":5,"user":{"displayName":"Zhou Zeqi","userId":"01018575624929983032"}},"outputId":"7f5dcb59-2c28-4543-99dc-387a4b7f430e"},"id":"_-x-YfAX-o5Q","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoints in: /content/checkpoints/qwen7b_bf16_offload\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}